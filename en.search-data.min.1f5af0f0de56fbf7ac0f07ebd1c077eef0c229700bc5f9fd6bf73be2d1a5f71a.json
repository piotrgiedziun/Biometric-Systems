[{"id":0,"href":"/biometric-systems/docs/labs/intro/","title":"Lab 1","section":"Labs","content":"Introduction #  Introduction to Machine Learning and Python - required to complete the course.\n  Pre-read (Required) #    https://www.kaggle.com/learn/python (Lessons 1-6)  https://www.kaggle.com/learn/intro-to-deep-learning (Lessons 1-3)  https://www.kaggle.com/learn/computer-vision (Lessons 1-4)  Literature (Optional) #   Christopher M. Bishop. (2007). Pattern Recognition and Machine Learning Sebastian Raschka (2019). Python Machine Learning: Machine Learning and Deep Learning with Python John M. Zelle, Guido van Rossum. (2016). Python Programming: An Introduction to Computer Science  Demo project #  This is a handwritten digit recognizer created during the class. It\u0026rsquo;s able to recognize single digit (0-9).\n  var canvas, ctx; var mouseX, mouseY, mouseDown = 0; var touchX, touchY; var lastX, lastY = -1; function drawLine(ctx, x, y, size) { if (lastX == -1) { lastX = x; lastY = y; } r = 255; g = 255; b = 255; a = 255; ctx.strokeStyle = \"rgba(\" + r + \",\" + g + \",\" + b + \",\" + a / 255 + \")\"; ctx.lineCap = \"round\"; ctx.beginPath(); ctx.moveTo(lastX, lastY); ctx.lineTo(x, y); ctx.lineWidth = size; ctx.stroke(); ctx.closePath(); lastX = x; lastY = y; } function clearCanvas(canvas, ctx) { ctx.clearRect(0, 0, canvas.width, canvas.height); document.getElementById(\"rightside\").innerHTML = \"\"; } function sketchpad_mouseDown() { mouseDown = 1; drawLine(ctx, mouseX, mouseY, 12); } function sketchpad_mouseUp() { mouseDown = 0; lastX = -1; lastY = -1; } function sketchpad_mouseMove(e) { getMousePos(e); if (mouseDown == 1) { drawLine(ctx, mouseX, mouseY, 12); } } function getMousePos(e) { if (!e) var e = event; if (e.offsetX) { mouseX = e.offsetX; mouseY = e.offsetY; } else if (e.layerX) { mouseX = e.layerX; mouseY = e.layerY; } } function sketchpad_touchStart() { getTouchPos(); drawLine(ctx, touchX, touchY, 12); event.preventDefault(); } function sketchpad_touchEnd() { lastX = -1; lastY = -1; } function sketchpad_touchMove(e) { getTouchPos(e); drawLine(ctx, touchX, touchY, 12); event.preventDefault(); } function getTouchPos(e) { if (!e) var e = event; if (e.touches) { if (e.touches.length == 1) { var touch = e.touches[0]; touchX = touch.pageX - touch.target.offsetLeft; touchY = touch.pageY - touch.target.offsetTop; } } } async function init() { canvas = document.getElementById(\"sketchpad\"); if (canvas.getContext) ctx = canvas.getContext(\"2d\"); if (ctx) { canvas.addEventListener(\"mousedown\", sketchpad_mouseDown, false); canvas.addEventListener(\"mousemove\", sketchpad_mouseMove, false); window.addEventListener(\"mouseup\", sketchpad_mouseUp, false); canvas.addEventListener(\"touchstart\", sketchpad_touchStart, false); canvas.addEventListener(\"touchend\", sketchpad_touchEnd, false); canvas.addEventListener(\"touchmove\", sketchpad_touchMove, false); } var loadDiv = document.getElementById(\"load\"); var demoDiv = document.getElementById(\"demo\"); loadDiv.style.display = \"none\"; model = await tf.loadLayersModel(\"../lab1/model.json\"); demoDiv.style.display = \"block\"; } function predict() { const imageData = ctx.getImageData(0, 0, 140, 140); var tfImg = tf.browser.fromPixels(imageData, 1); var smalImg = tf.image.resizeBilinear(tfImg, [28, 28]); smalImg = tf.cast(smalImg, \"float32\"); const tensor = smalImg .expandDims(1) .reshape([1, 28, 28, 1]) .div(tf.scalar(255)); console.log(\"xdf\", tensor.shape); const prediction = model.predict(tensor); const predictedValues = prediction.dataSync(); var isThereAnyPrediction = false; for (index = 0; index 0.5) { isThereAnyPrediction = true; document.getElementById(\"rightside\").innerHTML = index; } } if (!isThereAnyPrediction) { document.getElementById(\"rightside\").innerHTML = \"-\"; } }   .rightside { width: 140px; height: 125px; background-color: #def; border-radius: 4px; font-size: 70px; text-align: center; } .leftside { width: 150px; height: 200px; } #sketchpad { float: left; height: 140px; width: 140px; border: 2px solid #888; border-radius: 4px; position: relative; background-color: black; /* Necessary for correct mouse co-ords in Firefox */ } #demo { display: none; }        Content #   Introduction to the Google Colab environment, characteristics of working in an interactive environment Introduction to Python. The basics required to complete the course Introduction to Machine Learning (mean square error and gradient descent) Construction of a simple neural network using the TensorFlow library Introduction of the concepts of accuracy, confusion matrix and optimizer Implementation of a neural network (multilayer perceptron) on the MNIST dataset (preparing a dataset, dividing data into a test and training set, intro to loss functions, graph analysis) Implementation of the convolutional network for the same dataset. Interactive overview of convolutional layers, max pooling, activation and fully connected (dense)  "},{"id":1,"href":"/biometric-systems/docs/labs/face/","title":"Lab 2","section":"Labs","content":"Face detection and face recognition #  Face detection, face recognition, deep fakes.\n  Pre-read (Required) #    https://www.tensorflow.org/guide/keras/sequential_model  https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_hog.html  https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html  Demo #   Example web app\nContent #   Introduction to face detection algorithms (Histogram of Oriented Gradients, Haar Cascades, Deep Neural Network). The aim of the task is to get to know the methods and their strengths and weaknesses. Implementation of the HOG (Histogram of Oriented Gradients) algorithm to detect characteristic points of the face. Development and implementation of selected features and algorithms to verify the similarity (e.g. calculating the distance between face elements and their comparison). Implementation of the identification function based on the face pattern. A test set is provided for the task, on which the effectiveness of the solution should be verified. The function and algorithms used in this activity will be evaluated in the next class. The group with the highest score will receive additional points. Preparation of a set of training data for eye color recognition and model implementation. Comparison of the deep learning method with the traditional, previously implemented methods. Analysis of the safety and effectiveness of the implemented methods. Deep fake implementation and its practical applications.  "},{"id":2,"href":"/biometric-systems/docs/labs/iris/","title":"Lab 3","section":"Labs","content":"Identification system based on the characteristics of the iris #  Identifying the characteristics of the iris is a similar process to identifying it with the facial pattern and fingerprint. The system segments the image of the iris and then converts it into a pattern which is compared with the pattern. Iris readers often use an additional system to illuminate the eye with near-infrared light.\nPre-read (Required) #    https://www.tensorflow.org/addons/tutorials/losses_triplet  https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin  https://www.v7labs.com/blog/image-segmentation-guide  Content #   Introduction to the segmentation and related metrics (IoU, Dice score). Analysis of classic algorithms for automatic detection and segmentation of the iris (Geodesic Active Contours, SuperPixel Segmentation - SPS, Hough Transform). Construction of the U-NET network for iris segmentation on the CASIA V 4.0 set. Transformation of the iris image to the Cartesian coordinate system Extracting features with the Gabor filter. Analysis of the influence of light on the pattern. Use Hamming distance to calculate the distance between vectors Build iris embedding (a vector that represents the features extracted from the iris). Create Deep Neural Network that creates a mapping from iris images to a compact Euclidean space where distances directly represent iris similarity.  "}]